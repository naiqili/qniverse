diff --git a/LiLab/LiLab.egg-info/SOURCES.txt b/LiLab/LiLab.egg-info/SOURCES.txt
index 2f7e0cc..d841031 100644
--- a/LiLab/LiLab.egg-info/SOURCES.txt
+++ b/LiLab/LiLab.egg-info/SOURCES.txt
@@ -9,7 +9,6 @@ lilab/qlib/backtest/__init__.py
 lilab/qlib/backtest/benchmark.py
 lilab/qlib/data/__init__.py
 lilab/qlib/data/get_data.py
-lilab/qlib/data/handler.py
 lilab/qlib/scripts/__init__.py
 lilab/qlib/scripts/check_dump_bin.py
 lilab/qlib/scripts/collect_info.py
diff --git a/LiLab/lilab/qlib/backtest/benchmark.py b/LiLab/lilab/qlib/backtest/benchmark.py
index 0828293..47744f0 100644
--- a/LiLab/lilab/qlib/backtest/benchmark.py
+++ b/LiLab/lilab/qlib/backtest/benchmark.py
@@ -44,7 +44,17 @@ class BENCHBase:
             "fit_start_time": fit_time_split[0],
             "fit_end_time": fit_time_split[1],
             "instruments": self.instruments,
-            "label": self.label_code
+            "label": self.label_code,            
+            'infer_processors': [
+                {
+                'class': 'Fillna',
+                }
+            ],
+            'learn_processors':  [
+                {
+                'class': 'Fillna',
+                }
+            ],
         }
 
         if feat == "Alpha158":
@@ -97,7 +107,6 @@ class BENCHBase:
             },
         }
 
-
 class BENCH_A(BENCHBase):
     def __init__(self, 
                  time_span=("2010-01-01","2024-09-01"),
@@ -157,6 +166,106 @@ class BENCH_C(BENCHBase):
                  backtest_split,
                  **kwargs
         )
+        
+class BENCH_NOW(BENCHBase):
+    def __init__(self, 
+                 time_span=("2005-01-01","2024-12-01"),
+                 fit_time_split=("2005-01-01","2024-12-01"),
+                 train_split=("2005-01-01","2020-01-01"),
+                 valid_split=("2020-01-01","2024-11-01"),
+                 test_split=("2024-11-01", "2024-12-01"),
+                 backtest_split=("2024-11-01", "2024-12-01"),
+                 **kwargs
+                 ):
+        super(BENCH_NOW, self).__init__(
+                 time_span,
+                 fit_time_split,
+                 train_split,
+                 valid_split,
+                 test_split,
+                 backtest_split,
+                 **kwargs
+        )
+
+class BENCH_Set1(BENCHBase):
+    def __init__(self, 
+                 time_span=("2020-01-01","2024-11-01"),
+                 fit_time_split=("2020-01-01","2024-11-01"),
+                 train_split=("2020-01-01","2024-11-01"),
+                 valid_split=("2020-01-01","2024-11-01"),
+                 test_split=("2020-01-01","2024-11-01"),
+                 backtest_split=("2024-11-01","2024-12-01"),
+                 **kwargs
+                 ):
+        super(BENCH_Set1, self).__init__(
+                 time_span,
+                 fit_time_split,
+                 train_split,
+                 valid_split,
+                 test_split,
+                 backtest_split,
+                 **kwargs
+        )
+
+class BENCH_Set2(BENCHBase):
+    def __init__(self, 
+                 time_span=("2015-01-01","2020-01-01"),
+                 fit_time_split=("2015-01-01","2020-01-01"),
+                 train_split=("2015-01-01","2020-01-01"),
+                 valid_split=("2015-01-01","2020-01-01"),
+                 test_split=("2015-01-01","2020-01-01"),
+                 backtest_split=("2020-01-01","2021-01-01"),
+                 **kwargs
+                 ):
+        super(BENCH_Set2, self).__init__(
+                 time_span,
+                 fit_time_split,
+                 train_split,
+                 valid_split,
+                 test_split,
+                 backtest_split,
+                 **kwargs
+        )
+
+class BENCH_Set3(BENCHBase):
+    def __init__(self, 
+                 time_span=("2010-01-01","2015-01-01"),
+                 fit_time_split=("2010-01-01","2015-01-01"),
+                 train_split=("2010-01-01","2015-01-01"),
+                 valid_split=("2010-01-01","2015-01-01"),
+                 test_split=("2010-01-01","2015-01-01"),
+                 backtest_split=("2015-01-01","2016-01-01"),
+                 **kwargs
+                 ):
+        super(BENCH_Set3, self).__init__(
+                 time_span,
+                 fit_time_split,
+                 train_split,
+                 valid_split,
+                 test_split,
+                 backtest_split,
+                 **kwargs
+        )
+
+class BENCH_Set4(BENCHBase):
+    def __init__(self, 
+                 time_span=("2005-01-01","2010-01-01"),
+                 fit_time_split=("2005-01-01","2010-01-01"),
+                 train_split=("2005-01-01","2010-01-01"),
+                 valid_split=("2005-01-01","2010-01-01"),
+                 test_split=("2005-01-01","2010-01-01"),
+                 backtest_split=("2010-01-01","2011-01-01"),
+                 **kwargs
+                 ):
+        super(BENCH_Set3, self).__init__(
+                 time_span,
+                 fit_time_split,
+                 train_split,
+                 valid_split,
+                 test_split,
+                 backtest_split,
+                 **kwargs
+        )
 
 class BENCH_Step(BENCHBase):
     def __init__(self, 
diff --git a/TSLib/configs/config_patchtst.yaml b/TSLib/configs/config_patchtst.yaml
index 7a34eb6..d11146b 100644
--- a/TSLib/configs/config_patchtst.yaml
+++ b/TSLib/configs/config_patchtst.yaml
@@ -8,11 +8,11 @@ model_config: &model_config
   e_layers: 2
   factor: 3
   enc_in: 158
-  patch_len: 4
-  stride: 4
+  patch_len: 2
+  stride: 2
   c_out: 1
-  d_model: 128
-  d_ff: 128
+  d_model: 64
+  d_ff: 64
   n_heads: 4
   dropout: 0.1
   activation: 'gelu'
@@ -25,8 +25,8 @@ task:
     kwargs:
       lr: 0.0001
       n_epochs: 1000
-      max_steps_per_epoch: 100
-      early_stop: 3
+      max_steps_per_epoch: 10000
+      early_stop: 1
       seed: 2024
       logdir: output/patchtst
       model_type: PatchTST
@@ -45,4 +45,4 @@ task:
       market: csi300
       benchmark: SH000300 
       feat: Alpha158
-      label: r1
\ No newline at end of file
+      label: r1
diff --git a/TSLib/src/PatchTST.py b/TSLib/src/PatchTST.py
index f61fed2..9df8d44 100644
--- a/TSLib/src/PatchTST.py
+++ b/TSLib/src/PatchTST.py
@@ -258,11 +258,11 @@ class PatchTST(nn.Module):
 
     def forecast(self, x_enc):
         # Normalization from Non-stationary Transformer
-        # means = x_enc.mean(1, keepdim=True).detach()
-        # x_enc = x_enc - means
-        # stdev = torch.sqrt(
-        #     torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)
-        # x_enc /= stdev
+        means = x_enc.mean(1, keepdim=True).detach()
+        x_enc = x_enc - means
+        stdev = torch.sqrt(
+            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)
+        x_enc /= stdev
 
         # do patching and embedding
         x_enc = x_enc.permute(0, 2, 1)
@@ -282,6 +282,9 @@ class PatchTST(nn.Module):
         dec_out = dec_out.permute(0, 2, 1)
         dec_out = self.projection(dec_out)
 
+        # if torch.isnan(dec_out).any():
+        #     breakpoint()
+
         # De-Normalization from Non-stationary Transformer
         # dec_out = dec_out * \
         #           (stdev[:, 0, :].unsqueeze(1).repeat(1, self.pred_len, 1))
diff --git a/TSLib/src/model_backbone.py b/TSLib/src/model_backbone.py
index a92f0ce..8a93ddb 100644
--- a/TSLib/src/model_backbone.py
+++ b/TSLib/src/model_backbone.py
@@ -117,11 +117,18 @@ class QniverseModel(Model):
             data, label, index = batch["data"], batch["label"], batch["index"]
 
             feature = data[:, :, : -1]
+            
+            feature = torch.nan_to_num(feature, nan=0.0)
+            label = torch.nan_to_num(label, nan=0.0)
 
             # feature [batch_size, seq_len, num_fea]
             pred = self.model(feature).squeeze()
+            
+            pred = torch.nan_to_num(pred, nan=0.0)
+
             # pred [batch_size, horizon]
             loss = (pred - label).pow(2).mean()
+            # print(pred, label)
 
             loss.backward()
             self.optimizer.step()
@@ -147,9 +154,11 @@ class QniverseModel(Model):
             feature = data[:, :, : -1]
             hist_loss = data[:, : -data_set.horizon, -1:]
 
+            feature = torch.nan_to_num(feature, nan=0.0)
+            label = torch.nan_to_num(label, nan=0.0)
             with torch.no_grad():
                 pred = self.model(feature).squeeze()
-
+                pred = torch.nan_to_num(pred, nan=0.0)
 
             X = np.c_[
                 pred.cpu().numpy(),
diff --git a/TSLib/train.py b/TSLib/train.py
index a3e21de..b394bc5 100644
--- a/TSLib/train.py
+++ b/TSLib/train.py
@@ -3,6 +3,8 @@ import argparse
 import qlib
 import ruamel.yaml as yaml
 from qlib.utils import init_instance_by_config
+from qlib.workflow import R
+from qlib.workflow.record_temp import SignalRecord, PortAnaRecord
 from src.dataset import MTSDatasetH
 from lilab.qlib.backtest.benchmark import *
 import warnings
@@ -41,8 +43,55 @@ def main(seed, config_file="configs/config_wftnet.yaml"):
     # dataset = init_instance_by_config(config["task"]["dataset"])
     model = init_instance_by_config(config["task"]["model"])
 
-    # train model
-    model.fit(dataset)
+    # model.fit(dataset)
+
+    TOPK = 10
+    NDROP = 2
+    HT = 10
+
+    strategy_config = {
+        "class": "TopkDropoutStrategy",
+        "module_path": "qlib.contrib.strategy.signal_strategy",
+        "kwargs": {
+            "model": model,
+            "dataset": dataset,
+            "topk": TOPK,
+            "n_drop": NDROP,
+            "hold_thresh": HT,
+        },
+    }
+
+    # model.fit(dataset)
+    EXP_NAME = 'PatchTST'
+    URI = '/home/linq/finance/qniverse/mlrun1'
+
+    with R.start(experiment_name=EXP_NAME, uri=URI):
+        model.fit(dataset)
+        R.save_objects(trained_model=model)
+        rid = R.get_recorder().id
+        print(rid)
+
+    port_analysis_config = {
+        "executor": benchmark.executor_config,
+        "strategy": strategy_config,
+        "backtest": benchmark.backtest_config
+    }
+
+    # backtest and analysis
+    with R.start(experiment_name=EXP_NAME, uri=URI):
+        recorder = R.get_recorder(recorder_id=rid)
+        model = recorder.load_object("trained_model")
+
+        # prediction
+        recorder = R.get_recorder(recorder_id=rid)
+        ba_rid = recorder.id
+        sr = SignalRecord(model, dataset, recorder)
+        sr.generate()
+
+        # backtest & analysis
+        par = PortAnaRecord(recorder, port_analysis_config, "day")
+        par.generate()
+
 
 
 
